{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "using Pkg;\n",
    "using LSHFunctions\n",
    "#using StaticArrays\n",
    "using DataStructures\n",
    "using Flux\n",
    "using Zygote\n",
    "using MLDatasets\n",
    "using ImageView\n",
    "using LinearAlgebra\n",
    "using Plots;"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# load full training set\n",
    "train_x, train_y = MNIST.traindata();\n",
    "#train_x = permutedims(train_x,[3,2,1])\n",
    "#train_y = permutedims(train_y,[3,2,1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_x = permutedims(train_x,(3,2,1))\n",
    "x_train = reshape(train_x,(size(train_x)[1],prod(size(train_x)[2:end])));"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "println(train_y[1])\n",
    "Gray.(train_x[1,:,:])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAiVJREFUaAW9wT2IFgQABuAHemnI4aJFISgJwkDIIiqIsMLcajiKIEEIshosmgSHhhoUIW/IcIgCISHa+psKsp8hEKSSSAlyECon61Q+jMDT4RuO7w6/n5Pe54myKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIsZ3YQ5y17FLdiE3TiI5/EvDuAto6IsyqIsJrgDN+MRPIpb8YzV/sAhzOMSTuI7q0VZlEVZjHE/vsac8ZbwBgb4CH/hH/xmtSiLsiiLMc7iPOasdhyLeAL/4ajpRFmURVmM8Tf24Cn8hEOGfsZ2DLAZr5telEVZlMUEn+IYLmELXsQCBoZ+xcumF2VRFmUxhYuGLhjahY+xZHZRFmVRFjN4Ew/gMTyJr8wuyqIsymIGA7yEH/E+vsEJHMZV04myKIuymNEZvIAj2ImdWIcPcc5kURZlURZr8Al+xwK2YT/uxD78abwoi7IoizX6Bc/haRzBK7gb240XZVEWZXEDFnEUHyDYisfxreuLsiiLslije/EsHkQMncL3xouyKIuymNEmvIZ5bLDsCs5hyXhRFmVRFlPagB3YjY1GncA+fG6yKIuyKIsJ1mMz3sU9Rh3H2/gMS6YTZVEWZXEdt+E93Ie7jPoBC/gSl80myqIsymKFh7EHD+F2oy7jHezHwNpEWZRFWawwj3nLTuMLXMFBLLoxURZlURYr7MVe/58oi7Ioi7Ioi7Ioi7Ioi7IouwZsVVgTmd3ynQAAAABJRU5ErkJggg==",
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{FixedPointNumbers.N0f8}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "function comb(n, len) \n",
    "    Iterators.product(fill(BitArray([0,1]), len)...) |> collect |> vec \n",
    "end"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "comb (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#Parameters\n",
    "const batch_size = 16\n",
    "const k = 6\n",
    "const L = 5\n",
    "const sample_rate = 0.1 # 1%, proportion of nodes to sample from matrix"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "all_hash_codes = comb(1,k); #create all possible hash codes 2^k = 2^6 = 64"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Each layer is associated with `L` hash-tables and therefore `L` hash functions\n",
    "mutable struct Layer\n",
    "    theta::Matrix{Float64}\n",
    "    bias::Matrix{Float64}\n",
    "    hash_funs::Vector{SimHash{Float32}}\n",
    "    hash_tables::Vector{Dict{Tuple,CircularBuffer{Int64}}}\n",
    "end"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "function gen_layer(in_dim,out_dim,k=6,L=6,bin_size=10)\n",
    "    theta = randn(in_dim,out_dim) / 2\n",
    "    bias = randn(1,out_dim) / 5\n",
    "    cols = size(theta)[2] #number of columns/nodes\n",
    "    hash_funs = [LSHFunction(cossim, k) for i in 1:L]\n",
    "    hash_tables = Vector{Dict{Tuple,CircularBuffer{Int64}}}()\n",
    "    for i in 1:L #create L hash tables\n",
    "        ht_l::Dict{Tuple,CircularBuffer{Int64}} = Dict{Tuple,CircularBuffer{Int64}}((x) => CircularBuffer{Int64}(bin_size) for x in all_hash_codes)\n",
    "        push!(hash_tables,ht_l)\n",
    "        for j in 1:cols\n",
    "            hash_lj = hash_funs[i](theta[:,j])\n",
    "            hash_lj = Tuple(hash_lj)\n",
    "            push!(hash_tables[i][hash_lj],j)\n",
    "        end\n",
    "    end\n",
    "    layer = Layer(theta,bias,hash_funs,hash_tables)\n",
    "    return layer\n",
    "end"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "gen_layer (generic function with 4 methods)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "function update_htables(layer::Layer)\n",
    "    num_ht = length(layer.hash_funs)\n",
    "    cols = size(layer.theta)[2]\n",
    "    for i in 1:num_ht #iterate tables\n",
    "        for j in 1:cols\n",
    "            hash_lj = layer.hash_funs[i](layer.theta[:,j])\n",
    "            hash_lj = Tuple(hash_lj)\n",
    "            push!(layer.hash_tables[i][hash_lj],j)\n",
    "        end\n",
    "    end\n",
    "end"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "update_htables (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "layer1 = gen_layer(784,512)\n",
    "layer2 = gen_layer(512,10)\n",
    "layers = [layer1,layer2];"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "function get_batch(X, Y; batch_size=16)\n",
    "    indices = rand(1:size(X)[1],batch_size)\n",
    "    batch_x = X[indices,:]\n",
    "    batch_y = Y[indices]\n",
    "    return batch_x,batch_y\n",
    "end"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "get_batch (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "batch_x,batch_y = get_batch(x_train, train_y; batch_size=1);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# hash_funs::Vector{SimHash{Float32}}\n",
    "# hash_tables::Vector{Dict{Tuple,CircularBuffer{Int64}}}\n",
    "function sample_nodes(query::Vector, layer::Layer)\n",
    "    #`query` is the input vector for this layer\n",
    "    S = Set{Int64}()\n",
    "    for i in 1:L\n",
    "        # compute hash of query using each hashfun\n",
    "        q_hash = layer.hash_funs[i](query) |> Tuple\n",
    "        matches = layer.hash_tables[i][q_hash]\n",
    "        union!(S,matches)\n",
    "    end\n",
    "    return S |> collect\n",
    "end"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sample_nodes (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "function run_layer(X::Matrix,layer::Layer, cols::Vector{Int64}, rows::Vector{Int64})\n",
    "    #S is the subset\n",
    "    #println(\"$(size(X))  $(size(layer.theta[:,S]))  $(size(layer.bias))\")\n",
    "    e1 = isempty(cols)\n",
    "    e2 = isempty(rows)\n",
    "    bias = e1 ? layer.bias : layer.bias[:,cols]\n",
    "    theta = e1 ? layer.theta : layer.theta[:,cols]\n",
    "    #println(size(bias),size(theta))\n",
    "    theta = e2 ? theta : theta[rows,:]\n",
    "    #println(size(bias),size(theta))\n",
    "    #println(size(bias))\n",
    "    y_ = X * theta .+ bias #e.g. 1x784 * 784x36 = 1x36 + 1x36\n",
    "    #println(size(y_))\n",
    "    #println(y_)\n",
    "    #y = reshape(y_,1,:)\n",
    "    #println(size(y),size(y_))\n",
    "    return y_, cols\n",
    "end"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "run_layer (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1×10 Matrix{Float64}:\n",
       " 0.0285057  0.0750486  0.0815438  0.180232  …  0.0360265  0.113545  0.397267"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "function model(X::Array,layers::Vector{Layer}, S::Vector)\n",
    "    #layer-1\n",
    "    A1, c1 = run_layer(X,layers[1],S,Vector{Int64}([]))\n",
    "    A1 = Flux.normalise(A1;dims=ndims(A1), ϵ=1e-5)\n",
    "    A1 = NNlib.relu.(A1)\n",
    "    #layer-2\n",
    "    A2, c2 = run_layer(A1,layers[2],Vector{Int64}([]),c1)\n",
    "    A2 = Flux.normalise(A2;dims=ndims(A2), ϵ=1e-5)\n",
    "    A2 = NNlib.softmax(A2,dims=2)\n",
    "    return A2#,A1,S\n",
    "end"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "model (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "#run_layer(batch_x,layers[1],sort([x for x in S]),Vector{Int64}([]))\n",
    "model(batch_x, layers, [1,50,90,112,145,240,300,301,500,505])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1×10 Matrix{Float64}:\n",
       " 0.0285057  0.0750486  0.0815438  0.180232  …  0.0360265  0.113545  0.397267"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "lossfn(ŷ::Vector{Float64},y::Vector{Float64}) = -1.0 * LinearAlgebra.dot(log.(ŷ),y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "lossfn (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "#Y_true = Vector{Float64}(Flux.onehotbatch(train_y[1],0:9));\n",
    "function fix_label(y)\n",
    "    t = zeros(Float64,10)\n",
    "    t[y[]+1] = 1.0\n",
    "    return t\n",
    "end"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "fix_label (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "fix_label(batch_y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       " 0.0\n",
       " 1.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Calculating the gradients\n",
    "\n",
    "$$\\frac{\\partial Loss}{\\partial \\hat{y}} = $$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "batch_x,batch_y = get_batch(x_train,train_y;batch_size=1);\n",
    "S = sample_nodes(vec(batch_x),layers[1])\n",
    "A2 = model(batch_x,layers,S)\n",
    "y_true = fix_label(batch_y)\n",
    "g = Zygote.gradient(w -> lossfn(vec(model(rand(1,784),w,S)),[1.0,0,0,0,0,0,0,0,0,0]),layers)\n",
    "#g = Zygote.gradient((ypred,ytrue) -> lossfn(ypred,ytrue),(A2,batch_y))\n",
    "#println(g);"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "LoadError",
     "evalue": "UndefVarError: xs not defined",
     "traceback": [
      "UndefVarError: xs not defined",
      "",
      "Stacktrace:",
      "  [1] (::Zygote.var\"#442#443\")(#unused#::Nothing)",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/lib/array.jl:79",
      "  [2] (::Zygote.var\"#2383#back#444\"{Zygote.var\"#442#443\"})(Δ::Nothing)",
      "    @ Zygote ~/.julia/packages/ZygoteRules/OjfTt/src/adjoint.jl:59",
      "  [3] Pullback",
      "    @ ./abstractarray.jl:1056 [inlined]",
      "  [4] (::typeof(∂(copyto_axcheck!)))(Δ::Nothing)",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface2.jl:0",
      "  [5] Pullback",
      "    @ ./array.jl:540 [inlined]",
      "  [6] (::typeof(∂(Vector{Int64})))(Δ::Nothing)",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface2.jl:0",
      "  [7] Pullback",
      "    @ ./In[39]:7 [inlined]",
      "  [8] (::typeof(∂(model)))(Δ::Matrix{Float64})",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface2.jl:0",
      "  [9] Pullback",
      "    @ ./In[49]:5 [inlined]",
      " [10] (::typeof(∂(#24)))(Δ::Float64)",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface2.jl:0",
      " [11] (::Zygote.var\"#46#47\"{typeof(∂(#24))})(Δ::Float64)",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface.jl:41",
      " [12] gradient(f::Function, args::Vector{Layer})",
      "    @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface.jl:76",
      " [13] top-level scope",
      "    @ In[49]:5",
      " [14] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [15] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1094"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "g[1][1][][:theta]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "[x for x in g[1][2]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lossfn(vec(model(batch_x,layers,S)),y_true)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#batch_x,batch_y = get_batch(x_train,train_y;batch_size=1);\n",
    "#S = sample_nodes(vec(batch_x),layers[1])\n",
    "#A2,A1,S = model(batch_x,layers,S)\n",
    "#err = lossfn(A2,batch_y)\n",
    "W, b = randn(2, 3), randn(2);\n",
    "x = [-1.0,2,3]\n",
    "predict(W,b,x) = W*x .+ b;\n",
    "g = Zygote.gradient(x -> sum(predict(W,b,x)),)\n",
    "println(g)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "size(g[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "function train(epochs:Int64)\n",
    "    for i in 1:epochs\n",
    "        batch_x,batch_y = get_batch(x_train,train_y;batch_size=1);\n",
    "        S = sample_nodes(vec(X),layers[1])\n",
    "        A2,A1,S = model(batch_x,layers,S)\n",
    "        err = lossfn(A2,batch_y)\n",
    "        \n",
    "    end\n",
    "end"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "((x,y) -> x+y)(1,2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch = get_batch(train_x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch = reshape(batch,(16,784))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "collect(S)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "size(batch * layer1.theta[:,S])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('slide': conda)"
  },
  "interpreter": {
   "hash": "4ecd5b0def40d11926eb769baa0f5c5b6e342746dd5b6c5b03c4754dea9d1700"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}